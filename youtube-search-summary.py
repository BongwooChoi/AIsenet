import streamlit as st
import google.generativeai as genai
from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi
import os
from datetime import datetime, timedelta
import requests
import urllib.parse
import pandas as pd
import plotly.graph_objects as go
import yfinance as yf

# Streamlit ì•± ì„¤ì •
st.set_page_config(page_title="AI ê¸ˆìœµì •ë³´ ê²€ìƒ‰ ë° ë¶„ì„ ì„œë¹„ìŠ¤", page_icon="ğŸ¤–", layout="wide")

# API í‚¤ ì„¤ì •
genai.configure(api_key=st.secrets["GOOGLE_AI_STUDIO_API_KEY"])
youtube = build('youtube', 'v3', developerKey=st.secrets["YOUTUBE_API_KEY"])

# ê¸ˆìœµ ë„ë©”ì¸ë³„ í‚¤ì›Œë“œ ì •ì˜
FINANCE_DOMAINS = {
    "ì£¼ì‹": ["ì£¼ì‹", "ì¦ê¶Œ", "ë°°ë‹¹ì£¼", "ì£¼ê°€", "ìƒì¥", "ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "ëŸ¬ì…€", "ë‚˜ìŠ¤ë‹¥", "S&P500", "ë‹¤ìš°ì¡´ìŠ¤", "ë‹›ì¼€ì´"],
    "ë¶€ë™ì‚°": ["ë¶€ë™ì‚°", "ì•„íŒŒíŠ¸", "ì£¼íƒ", "ì˜¤í”¼ìŠ¤í…”", "ë¶„ì–‘", "ì²­ì•½", "ì¬ê±´ì¶•", "ì¬ê°œë°œ", "ì„ëŒ€", "ìƒê°€"],
    "ì½”ì¸": ["ì•”í˜¸í™”í", "ê°€ìƒí™”í", "ê°€ìƒìì‚°", "ë¹„íŠ¸ì½”ì¸", "ì´ë”ë¦¬ì›€", "ë¸”ë¡ì²´ì¸", "ì½”ì¸", "ê±°ë˜ì†Œ", "ì±„êµ´", "NFT"],
    "ì±„ê¶Œ/ê¸ˆë¦¬/í™˜ìœ¨": ["ì±„ê¶Œ", "êµ­ì±„", "íšŒì‚¬ì±„", "ê¸ˆë¦¬", "í•œêµ­ì€í–‰", "í•œì€", "ì—°ì¤€", "í™˜ìœ¨", "í†µí™”", "ë‹¬ëŸ¬", "ì—”í™”", "ìœ„ì•ˆí™”", "ìœ ë¡œí™”"],
    "ê²½ì œì¼ë°˜": ["ê²½ì œ", "ê¸ˆìœµ", "ë¬´ì—­", "ë¬¼ê°€", "ì¸í”Œë ˆì´ì…˜", "êµ­ë‚´ì´ìƒì‚°", "GDP", "ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜", "ìƒì‚°ìë¬¼ê°€ì§€ìˆ˜","CPI", "ê³ ìš©", "ìˆ˜ì¶œ", "ì†Œë¹„"]
}

# ì£¼ìš” ì£¼ì‹ ë¦¬ìŠ¤íŠ¸
MAJOR_STOCKS = [
    "Apple Inc. (AAPL)",
    "Microsoft Corporation (MSFT)",
    "Amazon.com Inc. (AMZN)",
    "Alphabet Inc. (GOOGL)",
    "Meta Platforms, Inc. (META)",
    "Tesla, Inc. (TSLA)",
    "NVIDIA Corporation (NVDA)",
    "JPMorgan Chase & Co. (JPM)",
    "Johnson & Johnson (JNJ)",
    "Visa Inc. (V)"
]

# ë‰´ìŠ¤ ê²€ìƒ‰ í•¨ìˆ˜ (Serp API ì‚¬ìš©)
def search_news(domain, additional_query, published_after, max_results=10):
    api_key = st.secrets["SERP_API_KEY"]
    keywords = " OR ".join(FINANCE_DOMAINS[domain])
    
    if additional_query:
        query = f"({keywords}) AND ({additional_query})"
    else:
        query = keywords
    
    encoded_query = urllib.parse.quote(query)
    
    url = f"https://serpapi.com/search.json?q={encoded_query}&tbm=nws&api_key={api_key}&num={max_results}&sort=date"
    
    if published_after:
        url += f"&tbs=qdr:{published_after}"
    
    response = requests.get(url)
    news_data = response.json()
    articles = news_data.get('news_results', [])
    
    unique_articles = []
    seen_urls = set()
    for article in articles:
        if article['link'] not in seen_urls:
            unique_articles.append({
                'title': article.get('title', ''),
                'source': {'name': article.get('source', '')},
                'description': article.get('snippet', ''),
                'url': article.get('link', ''),
                'content': article.get('snippet', '')
            })
            seen_urls.add(article['link'])
        if len(unique_articles) == max_results:
            break
    
    return unique_articles

# YouTube ê²€ìƒ‰ í•¨ìˆ˜
def search_videos_with_transcript(domain, additional_query, published_after, max_results=10):
    try:
        keywords = " OR ".join(FINANCE_DOMAINS[domain])
        query = f"({keywords}) {additional_query}".strip()
        
        # st.write(f"ê²€ìƒ‰ ì¿¼ë¦¬: {query}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        
        request = youtube.search().list(
            q=query,
            type='video',
            part='id,snippet',
            order='relevance',
            publishedAfter=published_after,
            maxResults=max_results
        )
        response = request.execute()

        videos_with_transcript = []
        for item in response['items']:
            video_id = item['id']['videoId']
            if get_video_transcript(video_id):
                videos_with_transcript.append(item)
        
        # st.write(f"ìë§‰ì´ ìˆëŠ” ë¹„ë””ì˜¤ ìˆ˜: {len(videos_with_transcript)}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        
        return videos_with_transcript[:max_results], len(response['items'])
    except Exception as e:
        st.error(f"YouTube ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return [], 0

# ì¢…ëª©ëª…ìœ¼ë¡œ ì¢…ëª© ì½”ë“œ ê²€ìƒ‰ í•¨ìˆ˜
def search_stock_symbol(stock_name):
    url = f"https://query2.finance.yahoo.com/v1/finance/search?q={urllib.parse.quote(stock_name)}&quotesCount=1&newsCount=0&enableFuzzyQuery=false&quotesQueryId=tss_match_phrase_query"
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers)
    data = response.json()
    
    if 'quotes' in data and len(data['quotes']) > 0:
        return data['quotes'][0]['symbol']
    return None

# ì¬ë¬´ì •ë³´ ê²€ìƒ‰ í•¨ìˆ˜ ìˆ˜ì •
def search_financial_info(stock_symbol):
    try:
        stock = yf.Ticker(stock_symbol)
        
        # ê¸°ë³¸ ì¬ë¬´ì œí‘œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        income_statement = stock.financials
        balance_sheet = stock.balance_sheet
        cash_flow = stock.cashflow
        
        return {
            'income_statement': income_statement.to_dict(),
            'balance_sheet': balance_sheet.to_dict(),
            'cash_flow_statement': cash_flow.to_dict()
        }
    except Exception as e:
        st.error(f"ì¬ë¬´ì •ë³´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ì¡°íšŒ ê¸°ê°„ ì„ íƒ í•¨ìˆ˜
def get_published_after(option):
    today = datetime.utcnow()
    if option == "ìµœê·¼ 1ì¼":
        return (today - timedelta(days=1)).isoformat("T") + "Z"
    elif option == "ìµœê·¼ 1ì£¼ì¼":
        return (today - timedelta(weeks=1)).isoformat("T") + "Z"
    elif option == "ìµœê·¼ 1ê°œì›”":
        return (today - timedelta(weeks=4)).isoformat("T") + "Z"
    elif option == "ìµœê·¼ 3ê°œì›”":
        return (today - timedelta(weeks=12)).isoformat("T") + "Z"
    elif option == "ìµœê·¼ 6ê°œì›”":
        return (today - timedelta(weeks=24)).isoformat("T") + "Z"
    elif option == "ìµœê·¼ 1ë…„":
        return (today - timedelta(weeks=52)).isoformat("T") + "Z"
    else:
        return None  # ì´ ê²½ìš° ì¡°íšŒ ê¸°ê°„ í•„í„°ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

# ìë§‰ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ (YouTube Transcript API ì‚¬ìš©)
def get_video_transcript(video_id):
    try:
        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])
        return ' '.join([entry['text'] for entry in transcript])
    except Exception as e:
        return None


# YouTube ì˜ìƒ ìš”ì•½ í•¨ìˆ˜
def summarize_video(video_id, video_title):
    try:
        transcript = get_video_transcript(video_id)
        if not transcript:
            return "ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ìš”ì•½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        model = genai.GenerativeModel('gemini-1.5-pro')
        prompt = f"ë‹¤ìŒ YouTube ì˜ìƒì˜ ì œëª©ê³¼ ë‚´ìš©ì„ ê°€ë…ì„± ìˆëŠ” í•œ í˜ì´ì§€ì˜ ë³´ê³ ì„œ í˜•íƒœë¡œ ìš”ì•½í•˜ì„¸ìš”. ìµœì¢… ê²°ê³¼ëŠ” í•œêµ­ì–´ë¡œ ë‚˜ì™€ì•¼ í•©ë‹ˆë‹¤.:\n\nì œëª©: {video_title}\n\n{transcript}"
        response = model.generate_content(prompt)

        if not response or not response.parts:
            feedback = response.prompt_feedback if response else "No response received."
            return f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {feedback}"

        summary = response.text
        return summary
    except Exception as e:
        return f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ë‰´ìŠ¤ ê¸°ì‚¬ ì¢…í•© ë¶„ì„ í•¨ìˆ˜
def analyze_news_articles(articles):
    try:
        model = genai.GenerativeModel('gemini-1.5-pro')
        
        # ëª¨ë“  ê¸°ì‚¬ì˜ ì œëª©ê³¼ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
        all_articles = "\n\n".join([f"ì œëª©: {article['title']}\në‚´ìš©: {article['content']}" for article in articles])
        
        prompt = f"""
ë‹¤ìŒì€ íŠ¹ì • ì£¼ì œì— ê´€í•œ ì—¬ëŸ¬ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì œëª©ê³¼ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ê¸°ì‚¬ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ê°€ë…ì„± ìˆëŠ” í•œ í˜ì´ì§€ì˜ ë³´ê³ ì„œë¥¼ ë‹¤ìŒ í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. ì£¼ìš” ì´ìŠˆ ìš”ì•½ (3-5ê°œì˜ í•µì‹¬ í¬ì¸íŠ¸)
2. ìƒì„¸ ë¶„ì„ (ê° ì£¼ìš” ì´ìŠˆì— ëŒ€í•œ ì‹¬ì¸µ ì„¤ëª…)
3. ë‹¤ì–‘í•œ ê´€ì  (ê¸°ì‚¬ë“¤ì—ì„œ ë‚˜íƒ€ë‚œ ì„œë¡œ ë‹¤ë¥¸ ì˜ê²¬ì´ë‚˜ í•´ì„)
4. ì‹œì‚¬ì  ë° í–¥í›„ ì „ë§

ë³´ê³ ì„œëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë¶„ì„ ì‹œ ê°ê´€ì„±ì„ ìœ ì§€í•˜ê³ , í¸í–¥ëœ ì˜ê²¬ì„ ì œì‹œí•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì£¼ì„¸ìš”.

ê¸°ì‚¬ ë‚´ìš©:
{all_articles}
"""
        response = model.generate_content(prompt)

        if not response or not response.parts:
            feedback = response.prompt_feedback if response else "No response received."
            return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {feedback}"

        analysis = response.text
        return analysis
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ì¬ë¬´ì •ë³´ ë¶„ì„
def analyze_financial_info(financial_data, stock_symbol, stock_name):
    try:
        model = genai.GenerativeModel('gemini-1.5-pro')
        
        # ì¬ë¬´ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        financial_info = ""
        for key, value in financial_data.items():
            financial_info += f"{key}:\n"
            if isinstance(value, dict):
                df = pd.DataFrame(value)
                financial_info += df.to_string() + "\n\n"
            else:
                financial_info += str(value) + "\n\n"
        
        prompt = f"""
ë‹¤ìŒì€ {stock_name} ({stock_symbol}) ì£¼ì‹ì˜ ì¬ë¬´ì •ë³´ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ì¸ ì¬ë¬´ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ë³´ê³ ì„œëŠ” ë‹¤ìŒ í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. ê¸°ì—… ê°œìš”
   - ì œê³µëœ ê¸°ì—… ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ê°œìš”ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
   - ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜í™”ëœ ë¬¸ì¥ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
2. ì£¼ìš” ì¬ë¬´ì§€í‘œ ë¶„ì„
   - ìˆ˜ìµì„±
   - ì„±ì¥ì„±
   - ì•ˆì •ì„±
3. ì£¼ì‹ ê°€ì¹˜í‰ê°€
4. ë¦¬ìŠ¤í¬ ìš”ì¸
5. í–¥í›„ ì „ë§ ë° íˆ¬ì ì˜ê²¬

ì£¼ìš” ì¬ë¬´ ë°ì´í„°ë¥¼ í‘œ í˜•íƒœë¡œ ì •ë¦¬í•˜ì—¬ ë³´ê³ ì„œì— í¬í•¨ì‹œì¼œì£¼ì„¸ìš”.
í‘œë¥¼ ì‘ì„±í•  ë•Œ ë‹¨ìœ„ë¥¼ ëª…ì‹œí•´ì£¼ì„¸ìš”.
ì†ìµ ê´€ë ¨ ì§€í‘œëŠ” ê¸ˆì•¡ê³¼ ë¹„ìœ¨ì„ ê°™ì´ í‘œì‹œí•´ì£¼ì„¸ìš”.
ìˆ˜ì¹˜ê°€ ì»¤ì„œ ì§€ìˆ˜ í˜•íƒœë¡œ í‘œí˜„ë˜ì§€ ì•Šê²Œ ë‹¨ìœ„ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.(ë°±ë§Œë‹¨ìœ„, ì–µë‹¨ìœ„ ë“±) 
í‘œëŠ” Markdown í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì¬ë¬´ ì •ë³´:
{financial_info}
"""
        response = model.generate_content(prompt)

        if not response or not response.parts:
            feedback = response.prompt_feedback if response else "No response received."
            return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {feedback}"

        analysis = response.text
        return analysis
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜
def download_summary_file(summary_text, file_name="summary.txt"):
    st.download_button(
        label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
        data=summary_text,
        file_name=file_name,
        mime="text/plain"
    )


# Streamlit ì•±
st.title("ğŸ¤– AI ê¸ˆìœµì •ë³´ ê²€ìƒ‰ ë° ë¶„ì„ ì„œë¹„ìŠ¤")
st.markdown("ì´ ì„œë¹„ìŠ¤ëŠ” ì„ íƒí•œ ê¸ˆìœµ ë„ë©”ì¸ì— ëŒ€í•œ YouTube ì˜ìƒ, ë‰´ìŠ¤, ê·¸ë¦¬ê³  ì£¼ì‹ ì¬ë¬´ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  AIë¥¼ ì´ìš©í•´ ë¶„ì„ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ê²€ìƒ‰ ì¡°ê±´ì„ ì„ íƒí•˜ê³  ê²€ìƒ‰í•´ë³´ì„¸ìš”.")

# ì‚¬ì´ë“œë°”ì— ê²€ìƒ‰ ì¡°ê±´ ë°°ì¹˜
with st.sidebar:
    st.header("ê²€ìƒ‰ ì¡°ê±´")
    source = st.radio("ê²€ìƒ‰í•  ì±„ë„ì„ ì„ íƒí•˜ì„¸ìš”:", ("YouTube", "ë‰´ìŠ¤", "ì¬ë¬´ì •ë³´"))
    if source in ["YouTube", "ë‰´ìŠ¤"]:
        domain = st.selectbox("ê¸ˆìœµ ë„ë©”ì¸ ì„ íƒ", list(FINANCE_DOMAINS.keys()))
        additional_query = st.text_input("ì¶”ê°€ ê²€ìƒ‰ì–´ (ì„ íƒ ì‚¬í•­)", key="additional_query")
        period = st.selectbox("ì¡°íšŒ ê¸°ê°„", ["ëª¨ë‘", "ìµœê·¼ 1ì¼", "ìµœê·¼ 1ì£¼ì¼", "ìµœê·¼ 1ê°œì›”", "ìµœê·¼ 3ê°œì›”", "ìµœê·¼ 6ê°œì›”", "ìµœê·¼ 1ë…„"], index=2)
    else:
        stock_input_method = st.radio("ì¢…ëª© ì„ íƒ ë°©ë²•", ("ëª©ë¡ì—ì„œ ì„ íƒ", "ì§ì ‘ ì…ë ¥"))
        if stock_input_method == "ëª©ë¡ì—ì„œ ì„ íƒ":
            stock_selection = st.selectbox("ì¢…ëª© ì„ íƒ", MAJOR_STOCKS)
            stock_input = stock_selection.split('(')[1].split(')')[0]  # ê´„í˜¸ ì•ˆì˜ ì¢…ëª© ì½”ë“œ ì¶”ì¶œ
        else:
            stock_input = st.text_input("ì¢…ëª©ì½”ë“œ(í‹°ì»¤) ì§ì ‘ ì…ë ¥ (ì˜ˆ: AAPL)")
    search_button = st.button("ê²€ìƒ‰ ì‹¤í–‰")

# ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ìš© ì„¸ì…˜ ìƒíƒœ
if 'search_results' not in st.session_state:
    st.session_state.search_results = {'videos': [], 'news': [], 'financial_info': {}}
    st.session_state.total_results = 0

# ìš”ì•½ ê²°ê³¼ ì €ì¥ìš© ì„¸ì…˜ ìƒíƒœ
if 'summary' not in st.session_state:
    st.session_state.summary = ""

# ê²€ìƒ‰ ì‹¤í–‰
if search_button:
    if source in ["YouTube", "ë‰´ìŠ¤"]:
        with st.spinner(f"{source}ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            published_after = get_published_after(period)
            
            if source == "YouTube":
                # YouTube ì˜ìƒ ê²€ìƒ‰
                videos, total_video_results = search_videos_with_transcript(domain, additional_query, published_after)
                st.session_state.search_results = {'videos': videos, 'news': [], 'financial_info': {}}
                st.session_state.total_results = total_video_results
                st.session_state.summary = ""  # YouTube ê²€ìƒ‰ ì‹œ ìš”ì•½ ì´ˆê¸°í™”
            
            elif source == "ë‰´ìŠ¤":
                # ë‰´ìŠ¤ ê²€ìƒ‰ ë° ìë™ ë¶„ì„
                news_articles = search_news(domain, additional_query, published_after, max_results=10)
                total_news_results = len(news_articles)
                st.session_state.search_results = {'videos': [], 'news': news_articles, 'financial_info': {}}
                st.session_state.total_results = total_news_results
                
                # ë‰´ìŠ¤ ê¸°ì‚¬ ìë™ ë¶„ì„
                with st.spinner("ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì¢…í•© ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    st.session_state.summary = analyze_news_articles(news_articles)
            
            if not st.session_state.total_results:
                st.warning(f"{source}ì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë„ë©”ì¸ì´ë‚˜ ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.")
    
    elif source == "ì¬ë¬´ì •ë³´":
        with st.spinner(f"{stock_input}ì˜ ì¬ë¬´ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            stock_symbol = search_stock_symbol(stock_input) if not stock_input.isalpha() else stock_input
            if stock_symbol:
                financial_info = search_financial_info(stock_symbol)
                st.session_state.search_results = {'videos': [], 'news': [], 'financial_info': financial_info}
                st.session_state.total_results = 1 if financial_info else 0
                
                if financial_info:
                    with st.spinner("ì¬ë¬´ì •ë³´ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        # ì¢…ëª©ëª… ê²°ì •
                        if stock_input_method == "ëª©ë¡ì—ì„œ ì„ íƒ":
                            stock_name = stock_selection.split('(')[0].strip()  # ê´„í˜¸ ì•ì˜ ì¢…ëª©ëª… ì¶”ì¶œ
                        else:
                            stock = yf.Ticker(stock_symbol)
                            stock_name = stock.info.get('longName', stock_symbol)  # yfinanceì—ì„œ ì¢…ëª©ëª… ê°€ì ¸ì˜¤ê¸°
                        
                        st.session_state.summary = analyze_financial_info(financial_info, stock_symbol, stock_name)
                else:
                    st.warning(f"{stock_input}ì˜ ì¬ë¬´ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ì¢…ëª©ëª… ë˜ëŠ” ì¢…ëª© ì½”ë“œì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                st.warning(f"{stock_input}ì— í•´ë‹¹í•˜ëŠ” ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
if source == "YouTube":
    st.subheader(f"ğŸ¦ ê²€ìƒ‰ëœ YouTube ì˜ìƒ")
    for video in st.session_state.search_results['videos']:
        col1, col2 = st.columns([1, 2])
        with col1:
            st.image(video['snippet']['thumbnails']['medium']['url'], use_column_width=True)
        with col2:
            st.subheader(video['snippet']['title'])
            st.markdown(f"**ì±„ë„ëª…:** {video['snippet']['channelTitle']}")
            st.write(video['snippet']['description'])
            video_url = f"https://www.youtube.com/watch?v={video['id']['videoId']}"
            st.markdown(f"[ì˜ìƒ ë³´ê¸°]({video_url})")
            
            video_id = video['id']['videoId']
            video_title = video['snippet']['title']
            if st.button(f"ğŸ“‹ ìš”ì•½ ë³´ê³ ì„œ ìš”ì²­", key=f"summarize_{video_id}"):
                with st.spinner("ì˜ìƒì„ ìš”ì•½í•˜ëŠ” ì¤‘..."):
                    summary = summarize_video(video_id, video_title)
                    st.session_state.summary = summary
        st.divider()

elif source == "ë‰´ìŠ¤":
    st.subheader(f"ğŸ“° ê²€ìƒ‰ëœ ë‰´ìŠ¤ ê¸°ì‚¬")
    for i, article in enumerate(st.session_state.search_results['news']):
        st.subheader(article['title'])
        st.markdown(f"**ì¶œì²˜:** {article['source']['name']}")
        st.write(article['description'])
        st.markdown(f"[ê¸°ì‚¬ ë³´ê¸°]({article['url']})")
        st.divider()

# ìš”ì•½ ê²°ê³¼ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
st.markdown('<div class="fixed-footer">', unsafe_allow_html=True)
col1, col2 = st.columns([0.85, 0.15])  # ì—´ì„ ë¹„ìœ¨ë¡œ ë¶„í• 
with col1:
    if source == "YouTube":
        st.subheader("ğŸ“‹ ì˜ìƒ ìš”ì•½ ë³´ê³ ì„œ")
    elif source == "ë‰´ìŠ¤":
        st.subheader("ğŸ“‹ ë‰´ìŠ¤ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
    else:
        st.subheader("ğŸ“ˆ ì¬ë¬´ì •ë³´ ë¶„ì„ ë³´ê³ ì„œ")
with col2:
    if st.session_state.summary:
        download_summary_file(st.session_state.summary)

if st.session_state.summary:
    st.markdown(st.session_state.summary, unsafe_allow_html=True)
else:
    if source == "YouTube":
        st.write("ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìš”ì•½í•  ì˜ìƒì„ ì„ íƒí•˜ì„¸ìš”.")
    elif source == "ë‰´ìŠ¤":
        st.write("ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.write("ì¬ë¬´ì •ë³´ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
st.markdown('</div>', unsafe_allow_html=True)

# ì£¼ì˜ì‚¬í•­ ë° ì•ˆë‚´
st.sidebar.markdown("---")
st.sidebar.markdown("**ì•ˆë‚´ì‚¬í•­:**")
st.sidebar.markdown("- ì´ ì„œë¹„ìŠ¤ëŠ” Google AI Studio API, YouTube Data API, Google Search API, SERP APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
st.sidebar.markdown("- ê²€ìƒ‰ ê²°ê³¼ì˜ í’ˆì§ˆê³¼ ë³µì¡ë„ì— ë”°ë¼ ì²˜ë¦¬ ì‹œê°„ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
st.sidebar.markdown("- ì €ì‘ê¶Œ ë³´í˜¸ë¥¼ ìœ„í•´ ê°œì¸ì ì¸ ìš©ë„ë¡œë§Œ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
st.sidebar.markdown("- ì œê³µë˜ëŠ” ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, íˆ¬ì ê²°ì •ì— ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.")
